"""
Omni-Vision Analytics API - FastAPI Application
"""
from fastapi import FastAPI, File, UploadFile, Form, HTTPException
from pydantic import BaseModel, Field
from typing import List, Optional, Any, Union
from contextlib import asynccontextmanager
from PIL import Image
import io
import logging

from .pipeline import OmniVisionPipeline

# Configure logging
logger = logging.getLogger(__name__)


# --- Pydantic Schemas ---

class BoundingBox(BaseModel):
    """Represents a bounding box [x1, y1, x2, y2]."""
    coords: List[float] = Field(..., min_length=4, max_length=4, description="[x1, y1, x2, y2]")


class Detection(BaseModel):
    """A single detected object."""
    label: str
    confidence: float
    box: List[float]
    has_mask: Optional[bool] = None


class AnalysisMeta(BaseModel):
    """Metadata about the analysis process."""
    processing_mode: str
    objects_detected: int
    generated_queries: Optional[List[str]] = None  # Queries generated by Gemma3


class AnalysisResponse(BaseModel):
    """Response model for the /analyze endpoint."""
    meta: AnalysisMeta
    detections: List[Detection]
    segmentation_available: bool
    masks_generated: Optional[int] = 0
    masks: Optional[List[Any]] = Field(default_factory=list, description="RLE dicts or base64 strings")
    mask_scores: Optional[List[float]] = Field(default_factory=list)
    mask_boxes: Optional[List[List[float]]] = Field(default_factory=list)
    mode_used: Optional[str] = "auto"
    mask_format: Optional[str] = "rle"
    queries_used: Optional[List[str]] = Field(default_factory=list, description="Queries used in smart_query mode")


class HealthResponse(BaseModel):
    """Response model for the /health endpoint."""
    status: str
    models_loaded: bool
    cuda_available: bool
    device: str
    sam3_enabled: bool


# --- Lifecycle Management ---

pipeline = OmniVisionPipeline()


@asynccontextmanager
async def lifespan(app: FastAPI):
    """Load models on startup."""
    print("Initializing Omni-Vision Pipeline...")
    try:
        await pipeline.load_models()
    except Exception as e:
        logger.error(f"Failed to load models: {e}")
        # Continue anyway - individual model wrappers handle graceful degradation
    yield
    print("Shutting down...")


# --- App Definition ---

app = FastAPI(
    title="Omni-Vision-Analytics",
    description="""
    Intelligent orchestration pipeline for computer vision model selection.
    
    **Use Cases:**
    - E-commerce cutout (background removal)
    - Privacy masking (faces, license plates)
    - Manufacturing visual inspection (defect regions)
    
    **Modes:**
    - `auto`: Detector-based flow → SAM3 box prompts
    - `query`: Text-prompted → fallback to detectors if empty
    """,
    version="3.0.0",
    lifespan=lifespan
)


# --- Endpoints ---

@app.get("/health", response_model=HealthResponse, tags=["System"])
async def health_check():
    """Health check endpoint to verify system status."""
    import torch
    
    sam3_enabled = True
    if hasattr(pipeline, 'sam_3') and hasattr(pipeline.sam_3, 'enabled'):
        sam3_enabled = pipeline.sam_3.enabled
    
    return {
        "status": "healthy", 
        "models_loaded": pipeline.models_loaded,
        "cuda_available": torch.cuda.is_available(),
        "device": "cuda" if torch.cuda.is_available() else "cpu",
        "sam3_enabled": sam3_enabled
    }


@app.post("/analyze", response_model=AnalysisResponse, tags=["Analysis"])
async def analyze_image(
    file: UploadFile = File(..., description="Image file to analyze"),
    user_text: Optional[str] = Form(None, description="Natural language input for smart query mode (Gemma3 generates queries)"),
    text_query: Optional[str] = Form(None, description="Direct text query for query mode"),
    mode: Optional[str] = Form(None, description="Inference mode: 'auto' (default), 'query', or 'smart_query'"),
    mask_format: Optional[str] = Form("rle", description="Mask format: 'rle' (default), 'png_base64', or 'none'")
):
    """
    Analyze an image using the intelligent model pipeline.
    
    **Modes:**
    - **auto** (default): YOLO → (RF-DETR if dense) → merge → SAM3 (box prompts)
    - **query**: SAM3 text-first → fallback to detectors if empty
    - **smart_query**: Gemma3 generates queries from natural language → SAM3 processes each
    
    **Mask formats:**
    - **rle** (default): Run-Length Encoded masks (COCO-compatible)
    - **png_base64**: Base64-encoded PNG images
    - **none**: Skip mask serialization (lightweight)
    
    **Use Cases:**
    - E-commerce cutout: `mode=auto`, no text_query
    - Privacy masking: `mode=auto` or `mode=query`, `text_query="face, license plate"`
    - Manufacturing inspection: `mode=query`, `text_query="scratch, defect"`
    - Natural language search: `mode=smart_query`, `user_text="この画像の中の車を見つけて"`
    """
    # Validate content type
    if not file.content_type or not file.content_type.startswith("image/"):
        raise HTTPException(status_code=400, detail="File must be an image.")
    
    # Validate mode if provided
    if mode and mode not in ("auto", "query", "smart_query"):
        raise HTTPException(
            status_code=400, 
            detail=f"Invalid mode '{mode}'. Must be 'auto', 'query', or 'smart_query'."
        )
    
    # Validate mask_format
    if mask_format and mask_format not in ("rle", "png_base64", "none"):
        raise HTTPException(
            status_code=400,
            detail=f"Invalid mask_format '{mask_format}'. Must be 'rle', 'png_base64', or 'none'."
        )

    try:
        # Read image bytes and convert to PIL Image
        image_bytes = await file.read()
        
        try:
            image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        except Exception:
            raise HTTPException(status_code=400, detail="Invalid image file.")
        
        # Run the pipeline
        result = await pipeline.analyze(
            image=image, 
            text_query=text_query,
            user_text=user_text,
            mode=mode,
            mask_format=mask_format or "rle"
        )
        
        return result

    except HTTPException:
        raise
    except Exception as e:
        # Log the actual error but return generic message
        logger.error(f"Analysis failed: {e}")
        raise HTTPException(
            status_code=500, 
            detail="An error occurred during image analysis. Please try again."
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
